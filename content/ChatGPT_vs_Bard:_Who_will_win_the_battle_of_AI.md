---
title: "ChatGPT vs Bard: Who will win the battle of AI"
date: 2023-02-23
---
![ChatGPT vs Bard](../images/2023-02-23-ChatGPT_vs_Bard%3A_Who_will_win_the_battle_of_AI/title.png)

# ChatGPT vs Bard: Who will win the battle of AI?
The moment that ChatGPT launched last November, I think we all realized how much of a game-changer this tool was. If you (somehow) haven’t heard of ChatGPT, it’s a chatbot AI built by OpenAI (the same company that made DALL E-2), capable of sustaining conversations with a reply feature. There were talks of this tool replacing Google itself, when Microsoft dropped some bombshell news: they would be integrating ChatGPT’s responses with Bing. The stage seemed to have been set for Microsoft to take over the search engine game. And in response, Google announced their own AI chatbot service: Bard. Through these last couple of months, I feel like we are seeing a war that’s the first of its kind- a war to develop the best AI.

Realistically, I think that neither ChatGPT nor Bard are ready for search engine integration. Although neural networks aren’t a total black box, when sent out into a production environment, you never know how people will exploit the system. We’ve already seen this, with reports of users trying to make ChatGPT realize it is an AI and feeding it certain biases.

> __Note:__ I think this is actually very beneficial as it exposes security risks and unfavorable responses, forcing OpenAI to re-tune their model.

Google and Bing work well since they solely show results that match the inquiry. If that information is wrong, it’s not Google’s fault, you just have to make sure the source is reliable. With these AI chatbots, there is no user selection — the information presented is shown as fact. A really simple example of this happened during Bard’s launch event, where the AI responded with incorrect information about the James Webb Telescope.


![Incorrect information given by Bard AI Chatbot](../images/2023-02-23-ChatGPT_vs_Bard%3A_Who_will_win_the_battle_of_AI/1.jpg "Incorrect information given by Bard AI Chatbot")


And this issue isn’t limited to Bard. If you ask ChatGPT for a table of information about different Bluetooth versions, a lot of the data is incorrect.

![Incorrect information given by ChatGPT AI Chatbot](../images/2023-02-23-ChatGPT_vs_Bard%3A_Who_will_win_the_battle_of_AI/2.png "IIncorrect information given by ChatGPT AI Chatbot")

So then the question becomes: how do you prevent factual inaccuracies? Well, I think that can only come from what both Microsoft and Google are trying to do. By leveraging the top search results for a given phrase, the chatbot is more likely to give a better response based on that top search result.

## Who wins the battle?
For me, the clear answer is Microsoft. From initial testing, ChatGPT feels like a more polished and more powerful AI, compared to Bard. Sure, being the dominant chatbot helps, but it also means that Microsoft has had significantly more time to start integrating ChatGPT into Bing. On the contrary, it feels like Google’s hand was forced to reveal Bard, and that tends to not work out. I strongly believe Microsoft has invested more then they are revealing into this Bard + Bing project, and will release it before Google.

## Who wins the war?
That being said, there is a reason that Google is the superior search engine. The inquiry and result matching system is much more refined, and you usually don’t need to go past the first few links to get the information you need. Google has worked on perfecting their search algorithm for years. An algorithm with such a high standard means the foundation for Google is more solid than it is for Microsoft. Over time, Bard will get better. It will be trained on more data and the call/response system will only increase in quality. Bing just isn’t there yet, and I’m not sure if it will ever be there.

That being said, these predictions could be completely incorrect. But, it does lead to a plethora of questions. How will these models retrain every time there is new data? What if a model has a certain political bias based on the data it’s given? These all have to be answered before any AI model can be pushed into production. Companies are innovating every day, and soon enough, there will be another groundbreaking technology accompanied by another war between tech giants.

## A Quick Note About AI "Coming Alive"
Before I finish, I want to address whether these chatbots can “become alive.” It’s certainly possible in the future, but with what we have right now, there is absolutely no way. A model, such as ChatGPT, works by getting in some data and creating a suitable output based on that data. We’ve seen stories about ChatGPT and other AI models “gaining consciousness,” but that’s simply a model reacting to its previous input. It’s unnerving for sure, but it’s definitely not world-threating. In fact, I think it would be pretty cool to see an AI able to react to a chaotic environment, although that seems to be pretty far down the future. Bottom line: no, AI can’t come alive.